from croniter import croniter
from sqlalchemy import select, insert, update, delete, desc, Engine
from datetime import datetime
import threading

from app.core.sh.ssh_client import SSHClient

from . import models, schemas
from .scheduler import scheduler
from app.core.ws.ws_manager import ws_manager
from app.core.interrupt.execution_manager import execution_manager, ExecutionCancelledError

from app.modules.node.models import nodes_table


# ä»»åŠ¡ç®¡ç†
def create_cron_job(engine: Engine, job: schemas.CronJobCreate) -> dict:
    data = job.model_dump()
    stmt = insert(models.cron_jobs_table).values(**data)
    with engine.begin() as conn:
        result = conn.execute(stmt)
        job_id = result.inserted_primary_key[0]
        return {"id": job_id, **data}

def get_cron_jobs(engine: Engine, node_ids: list[int] = None) -> list[dict]:
    stmt = (
        select(models.cron_jobs_table)
        .join(
            nodes_table,
            models.cron_jobs_table.c.node_id == nodes_table.c.id
        )
        .where(nodes_table.c.is_active.is_(True))
        .order_by(models.cron_jobs_table.c.name, nodes_table.c.name)
    )

    # å¤šèŠ‚ç‚¹ç­›é€‰
    if node_ids and len(node_ids) > 0:
        stmt = stmt.where(models.cron_jobs_table.c.node_id.in_(node_ids))
    with engine.connect() as conn:
        result = conn.execute(stmt)
        jobs = []
        for row in result.mappings():
            job_dict = dict(row)

            # è®¡ç®—ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
            try:
                if job_dict['is_active']:
                    cron = croniter(job_dict['schedule'], datetime.now())
                    next_run = cron.get_next(datetime)
                    job_dict['next_run'] = next_run.isoformat()
                else:
                    job_dict['next_run'] = None
            except Exception:
                job_dict['next_run'] = None

            jobs.append(job_dict)
        return jobs

def execute_job(engine: Engine, job_id: int, triggered_by: str = "manual") -> dict:
    """æ‰§è¡Œä»»åŠ¡å¹¶å®æ—¶ä¿å­˜æ—¥å¿—"""
    # è·å–ä»»åŠ¡å’ŒèŠ‚ç‚¹ï¼ˆæå‰éªŒè¯ï¼‰
    with engine.connect() as conn:
        job_stmt = select(models.cron_jobs_table).where(models.cron_jobs_table.c.id == job_id)
        job = conn.execute(job_stmt).mappings().first()
        if not job:
            scheduler.remove_job(job_id, 'è¯¥ä»»åŠ¡ä¸å­˜åœ¨')
            raise ValueError(f"ä»»åŠ¡ {job_id} ä¸å­˜åœ¨ï¼Œå·²ç§»é™¤è®¡åˆ’")

        node_stmt = select(nodes_table).where(nodes_table.c.id == job['node_id'])
        node = conn.execute(node_stmt).mappings().first()
        if not node:
            scheduler.remove_job(job_id, f"ä»»åŠ¡ {job_id} çš„èŠ‚ç‚¹{job['node_id']}ä¸å­˜åœ¨")
            raise ValueError(f"ä»»åŠ¡ {job_id} çš„èŠ‚ç‚¹{job['node_id']}ä¸å­˜åœ¨ï¼Œå·²ç§»é™¤è®¡åˆ’")

    # åˆ›å»ºæ‰§è¡Œè®°å½•
    stmt = insert(models.job_executions_table).values(
        job_id=job_id,
        start_time=datetime.now(),
        status="running",
        triggered_by=triggered_by
    )
    with engine.begin() as conn:
        result = conn.execute(stmt)
        execution_id = result.inserted_primary_key[0]
        print(f"âœ… ä»»åŠ¡è°ƒåº¦ï¼šæ—¶é—´ï¼ˆ{datetime.now().replace(second=0, microsecond=0)}ï¼‰ï¼Œè®¾å¤‡ï¼ˆ{node['name']}ï¼‰ï¼Œä»»åŠ¡ï¼ˆ{job['name']}ï¼‰ï¼Œè§¦å‘æ–¹å¼ï¼ˆ{triggered_by}ï¼‰")

    def run_task():
        ssh = None
        output_buffer = []  # å½“å‰æœªä¿å­˜çš„è¾“å‡ºç‰‡æ®µ
        error_buffer = []   # å½“å‰æœªä¿å­˜çš„é”™è¯¯ç‰‡æ®µ
        out_len = 2000 #è¿½åŠ å…¥åº“åˆ†ç‰‡é•¿åº¦
        error_len = 1000
        try:
            # åˆ›å»ºåœæ­¢äº‹ä»¶
            execution_manager.create_execution(execution_id)
            # åˆå§‹åŒ–æ•°æ®åº“è®°å½•ï¼ˆç©ºæ—¥å¿—ï¼‰
            _init_execution_log(engine, execution_id)

            from app.modules.node.schemas import NodeRead
            ssh = SSHClient(NodeRead(**node))
            ssh.connect()

            initial_log = {"status": "running", "output": "æ­£åœ¨è¿æ¥...\n", "error": "", "end_time": None}
            ws_manager.send_log_sync(execution_id, initial_log)

            _, stdout, stderr = ssh.client.exec_command(job['command'], timeout=60)

            while True:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ–­
                if execution_manager.should_stop(execution_id):
                    raise ExecutionCancelledError("ä»»åŠ¡å·²è¢«ç”¨æˆ·ä¸­æ–­")

                # å¤„ç† stdout
                if stdout.channel.recv_ready():
                    line = stdout.channel.recv(1024).decode('utf-8', errors='replace')
                    if line:
                        output_buffer.append(line)
                        # å®æ—¶æ¨é€åˆ° WebSocket
                        log_data = {
                            "status": "running",
                            "output": line,
                            "error": "",
                            "end_time": None
                        }
                        ws_manager.send_log_sync(execution_id, log_data)

                        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜åˆ°æ•°æ®åº“
                        if len("".join(output_buffer)) >= out_len:
                            _save_and_clear_buffer(engine, execution_id, output_buffer, [], "running")

                # å¤„ç† stderr
                if stderr.channel.recv_stderr_ready():
                    line = stderr.channel.recv_stderr(1024).decode('utf-8', errors='replace')
                    if line:
                        error_buffer.append(line)
                        # å®æ—¶æ¨é€åˆ° WebSocket
                        log_data = {
                            "status": "running",
                            "output": "",
                            "error": line,
                            "end_time": None
                        }
                        ws_manager.send_log_sync(execution_id, log_data)

                        # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¿å­˜åˆ°æ•°æ®åº“
                        if len("".join(error_buffer)) >= error_len:
                            _save_and_clear_buffer(engine, execution_id, [], error_buffer, "running")

                if stdout.channel.exit_status_ready():
                    # stdout å…œåº•
                    while stdout.channel.recv_ready():
                        line = stdout.channel.recv(4096).decode("utf-8", errors="replace")
                        if line:
                            output_buffer.append(line)
                            log_data = {"status": "running", "output": line, "error": "", "end_time": None}
                            ws_manager.send_log_sync(execution_id, log_data)

                    # stderr å…œåº•
                    while stderr.channel.recv_stderr_ready():
                        line = stderr.channel.recv_stderr(4096).decode("utf-8", errors="replace")
                        if line:
                            error_buffer.append(line)
                            log_data = {"status": "running", "output": "", "error": line, "end_time": None}
                            ws_manager.send_log_sync(execution_id, log_data)

                    break

            # ä¿å­˜å‰©ä½™æ—¥å¿—
            if output_buffer:
                _save_and_clear_buffer(engine, execution_id, output_buffer, [], "running")
            if error_buffer:
                _save_and_clear_buffer(engine, execution_id, [], error_buffer, "running")

            exit_code = stdout.channel.recv_exit_status()
            status = "success" if exit_code == 0 else "failed"

            # æ›´æ–°æœ€ç»ˆçŠ¶æ€
            _update_execution_final_status(engine, execution_id, status)

            final_output = "".join(output_buffer)  # æ­¤æ—¶ buffer å·²æ¸…ç©ºï¼Œä½†æˆ‘ä»¬éœ€è¦æœ€ç»ˆå†…å®¹ç”¨äº WebSocket
            final_error = "".join(error_buffer)

            final_log = {
                "status": status,
                "output": final_output,
                "error": final_error,
                "end_time": datetime.now().isoformat()
            }
            ws_manager.send_log_sync(execution_id, final_log)

        except ExecutionCancelledError as e:
            error_msg = str(e)
            # ä¿å­˜å‰©ä½™è¾“å‡ºæ—¥å¿—
            if output_buffer:
                _save_and_clear_buffer(engine, execution_id, output_buffer, [], "cancelled")
            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            if error_msg:
                _save_and_clear_buffer(engine, execution_id, [], [error_msg], "cancelled")

            _update_execution_final_status(engine, execution_id, "cancelled")

            final_output = "".join(output_buffer) if 'output_buffer' in locals() else ""
            final_error = error_msg

            final_log = {
                "status": "cancelled",
                "output": final_output,
                "error": final_error,
                "end_time": datetime.now().isoformat()
            }
            ws_manager.send_log_sync(execution_id, final_log)

        except Exception as e:
            error_msg = str(e)
            # ä¿å­˜é”™è¯¯ä¿¡æ¯
            _save_and_clear_buffer(engine, execution_id, [], [error_msg], "failed")
            _update_execution_final_status(engine, execution_id, "failed")

            final_log = {
                "status": "failed",
                "output": "",
                "error": error_msg,
                "end_time": datetime.now().isoformat()
            }
            ws_manager.send_log_sync(execution_id, final_log)

        finally:
            if ssh:
                ssh.close()
            # æ¸…ç†èµ„æº
            execution_manager.cleanup(execution_id)
            ws_manager.cleanup(execution_id)

    threading.Thread(target=run_task, daemon=True).start()
    return get_execution(engine, execution_id)
def _init_execution_log(engine: Engine, execution_id: int):
    """åˆå§‹åŒ–æ‰§è¡Œæ—¥å¿—è®°å½•ï¼ˆç©ºå†…å®¹ï¼‰"""
    stmt = (
        update(models.job_executions_table)
        .where(models.job_executions_table.c.id == execution_id)
        .values(
            output="",
            error="",
            status="running",
            end_time=None
        )
    )
    with engine.begin() as conn:
        conn.execute(stmt)
def _save_and_clear_buffer(engine: Engine, execution_id: int, output_buffer: list, error_buffer: list, status: str):
    """ä¿å­˜ç¼“å†²åŒºå†…å®¹å¹¶æ¸…ç©º"""
    if not output_buffer and not error_buffer:
        return

    output_str = "".join(output_buffer)
    error_str = "".join(error_buffer)

    # è¿½åŠ åˆ°æ•°æ®åº“
    stmt = (
        update(models.job_executions_table)
        .where(models.job_executions_table.c.id == execution_id)
        .values(
            output=models.job_executions_table.c.output + output_str,
            error=models.job_executions_table.c.error + error_str,
            status=status,
            end_time=datetime.now() if status in ["success", "failed", "cancelled"] else None
        )
    )
    with engine.begin() as conn:
        conn.execute(stmt)

    # ğŸ‘‡ å…³é”®ï¼šæ¸…ç©ºç¼“å†²åŒº
    output_buffer.clear()
    error_buffer.clear()
def _update_execution_final_status(engine: Engine, execution_id: int, status: str):
    """æ›´æ–°æœ€ç»ˆçŠ¶æ€å’Œç»“æŸæ—¶é—´"""
    stmt = (
        update(models.job_executions_table)
        .where(models.job_executions_table.c.id == execution_id)
        .values(
            status=status,
            end_time=datetime.now()
        )
    )
    with engine.begin() as conn:
        conn.execute(stmt)

def update_cron_job(engine, job_id: int, update_data: dict) -> bool:
    with engine.connect() as conn:
        stmt = (
            update(models.cron_jobs_table)
            .where(models.cron_jobs_table.c.id == job_id)
            .values(**update_data)
        )
        result = conn.execute(stmt)
        conn.commit()
        return result.rowcount > 0
def get_cron_job(engine, job_id: int):
    with engine.connect() as conn:
        query = models.cron_jobs_table.select().where(models.cron_jobs_table.c.id == job_id)
        result = conn.execute(query).fetchone()
        return result._asdict() if result else None

# è·å–æ‰§è¡Œè®°å½•
def get_executions(engine: Engine, job_id: int, limit: int = 10) -> list[dict]:
    stmt = (
        select(models.job_executions_table)
        .where(models.job_executions_table.c.job_id == job_id)
        .order_by(models.job_executions_table.c.start_time.desc())
        .limit(limit)
    )
    with engine.connect() as conn:
        result = conn.execute(stmt)
        return [dict(row) for row in result.mappings()]

def get_execution(engine: Engine, execution_id: int) -> dict:
    stmt = select(models.job_executions_table).where(models.job_executions_table.c.id == execution_id)
    with engine.connect() as conn:
        result = conn.execute(stmt).mappings().first()
        return dict(result) if result else None

# æ‰¹é‡æ‰§è¡Œ
def execute_jobs(engine: Engine, request: schemas.ManualExecutionRequest) -> list[dict]:
    results = []
    for job_id in request.job_ids:
        execution = execute_job(engine, job_id, "manual")
        results.append(execution)
    return results

def toggle_job_status(engine: Engine, job_id: int, is_active: bool) -> bool:
    stmt = (
        update(models.cron_jobs_table)
        .where(models.cron_jobs_table.c.id == job_id)
        .values(is_active=is_active)
    )
    with engine.begin() as conn:
        result = conn.execute(stmt)
        if result.rowcount == 0:
            return False

        job_stmt = select(models.cron_jobs_table).where(models.cron_jobs_table.c.id == job_id)
        job = conn.execute(job_stmt).mappings().first()
        if not job:
            return False

        if is_active:
            scheduler.add_job(job)
        else:
            scheduler.remove_job(job_id, job['name'])
        return True

def remove_job(engine: Engine, job_id: int) -> bool:
    with engine.begin() as conn:
        job_stmt = select(models.cron_jobs_table).where(models.cron_jobs_table.c.id == job_id)
        job = conn.execute(job_stmt).mappings().first()
        if not job:
            return False

        stmt = delete(models.cron_jobs_table).where(models.cron_jobs_table.c.id == job_id)
        result = conn.execute(stmt)
        scheduler.remove_job(job_id, job['name'])
        return result.rowcount > 0

def get_next_crons(cron: schemas.CronReq) -> list[dict]:
    cron = croniter(cron.cron, datetime.now())
    # è·å–æœ€è¿‘çš„5æ¬¡æ‰§è¡Œæ—¶é—´
    recent_runs = []
    for _ in range(5):
        next_run = cron.get_next(datetime)
        recent_runs.append(schemas.CronNextRes(next_run=next_run.isoformat()))
    return recent_runs
