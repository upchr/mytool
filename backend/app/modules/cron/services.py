import asyncio

from croniter import croniter
from fastapi import HTTPException
from sqlalchemy import select, insert, update, delete, desc
from sqlalchemy.engine import Engine
from datetime import datetime
import threading

from sqlalchemy.exc import IntegrityError

from . import models, schemas
from .models import nodes_table, credential_templates_table
from .schemas import NodeCreate, CredentialTemplateCreate
from .ssh_client import SSHClient
from .scheduler import scheduler
from .ws_manager import ws_manager
from .execution_manager import execution_manager, ExecutionCancelledError


# èŠ‚ç‚¹ç®¡ç†
def create_node(engine: Engine, node: schemas.NodeCreate) -> dict:
    data = node.model_dump()
    stmt = insert(models.nodes_table).values(**data)
    with engine.begin() as conn:
        result = conn.execute(stmt)
        node_id = result.inserted_primary_key[0]
        return {"id": node_id, **data}  # âœ… è¿”å›å®Œæ•´å¯¹è±¡

def get_nodes(engine: Engine, active_only: bool) -> list[dict]:
    stmt = select(models.nodes_table).order_by(models.nodes_table.c.name )
    if active_only:
        stmt = stmt.where(models.nodes_table.c.is_active == True)
    with engine.connect() as conn:
        result = conn.execute(stmt)
        return [dict(row) for row in result.mappings()]

def get_node(engine: Engine, node_id: int) -> dict:
    stmt = select(models.nodes_table).where(models.nodes_table.c.id == node_id)
    with engine.connect() as conn:
        result = conn.execute(stmt).mappings().first()
        return dict(result) if result else None

def delete_node(engine: Engine, node_id: int) -> bool:
    stmt = delete(models.nodes_table).where(models.nodes_table.c.id == node_id)
    with engine.begin() as conn:
        result = conn.execute(stmt)
        return result.rowcount > 0
def toggle_node_status(engine: Engine, node_id: int, is_active: bool) -> bool:
    with engine.begin() as conn:
        # 1ï¸âƒ£ æ›´æ–°èŠ‚ç‚¹çŠ¶æ€
        result = conn.execute(
            update(models.nodes_table)
            .where(models.nodes_table.c.id == node_id)
            .values(is_active=is_active)
        )
        if result.rowcount == 0:
            return False

        # 2ï¸âƒ£ æŸ¥è¯¢è¯¥èŠ‚ç‚¹ä¸‹æ‰€æœ‰ä»»åŠ¡
        jobs = conn.execute(
            select(models.cron_jobs_table)
            .where(models.cron_jobs_table.c.node_id == node_id)
        ).mappings().all()

    # 3ï¸âƒ£ åŒæ­¥è°ƒåº¦å™¨ï¼ˆäº‹åŠ¡å¤–ï¼‰
    for job in jobs:
        if is_active:
            # èŠ‚ç‚¹æ¢å¤ï¼šåªæ¢å¤åŸæœ¬å¯ç”¨çš„ä»»åŠ¡
            if job["is_active"]:
                scheduler.add_job(job)
        else:
            # èŠ‚ç‚¹åœç”¨ï¼šå…¨éƒ¨ä»è°ƒåº¦å™¨ç§»é™¤
            scheduler.remove_job(job["id"], job["name"])

    return True

def update_node(engine: Engine, node_id: int, node: NodeCreate) -> dict:
    stmt = (
        update(nodes_table)
        .where(nodes_table.c.id == node_id)
        .values(**node.__dict__)  # å°†NodeCreateå¯¹è±¡è½¬ä¸ºå­—å…¸
    )
    with engine.begin() as conn:
        result = conn.execute(stmt)
        if result.rowcount == 0:
            return None
        # è¿”å›æ›´æ–°åçš„æ•°æ®
        select_stmt = select(nodes_table).where(nodes_table.c.id == node_id)
        row = conn.execute(select_stmt).mappings().first()
        return dict(row)

def batch_delete_nodes(engine: Engine, node_ids: list[int]) -> int:
    """æ‰¹é‡åˆ é™¤èŠ‚ç‚¹ï¼Œè¿”å›æˆåŠŸåˆ é™¤çš„æ•°é‡"""
    deleted_count = 0

    with engine.begin() as conn:
        for node_id in node_ids:
            try:
                # 1. åˆ é™¤å…³è”çš„å®šæ—¶ä»»åŠ¡
                conn.execute(
                    delete(models.cron_jobs_table)
                    .where(models.cron_jobs_table.c.node_id == node_id)
                )

                # 2. åˆ é™¤èŠ‚ç‚¹
                result = conn.execute(
                    delete(models.nodes_table)
                    .where(models.nodes_table.c.id == node_id)
                )

                if result.rowcount > 0:
                    deleted_count += 1

            except Exception as e:
                print(f"åˆ é™¤èŠ‚ç‚¹ {node_id} å¤±è´¥: {e}")
                # ç»§ç»­å¤„ç†å…¶ä»–èŠ‚ç‚¹

    return deleted_count

def create_credential_template(engine, template_data):
    table = models.credential_templates_table

    # è½¬ä¸ºå­—å…¸ï¼ˆå…¼å®¹ Pydantic æ¨¡å‹ï¼‰
    data = template_data if isinstance(template_data, dict) else template_data.model_dump()

    with engine.connect() as conn:
        try:
            # æ’å…¥
            stmt = insert(table).values(**data)
            result = conn.execute(stmt)
            conn.commit()

            # è·å–åˆšæ’å…¥çš„è®°å½•
            new_id = result.inserted_primary_key[0]
            query = select(table).where(table.c.id == new_id)
            row = conn.execute(query).fetchone()
            return row._asdict() if row else None
        except IntegrityError as e:
            conn.rollback()  # å›æ»šäº‹åŠ¡
            # æ£€æŸ¥æ˜¯å¦æ˜¯åç§°é‡å¤
            if "UNIQUE constraint failed: credential_templates.name" in str(e) or "Duplicate entry" in str(e):
                raise HTTPException(
                    status_code=400,
                    detail="å‡­æ®æ¨¡æ¿åç§°å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–åç§°"
                )
            else:
                raise HTTPException(
                    status_code=400,
                    detail="æ•°æ®æ ¡éªŒå¤±è´¥"
                )
        except Exception as e:
            conn.rollback()
            raise HTTPException(
                status_code=500,
                detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"
)

def get_credential_templates(engine):
    """
    è·å–æ‰€æœ‰å‡­æ®æ¨¡æ¿åˆ—è¡¨
    :param engine: SQLAlchemy å¼•æ“
    :return: list[dict]
    """
    table = models.credential_templates_table

    with engine.connect() as conn:
        query = select(table).order_by(table.c.name,desc(table.c.id))
        result = conn.execute(query)
        return [row._asdict() for row in result.fetchall()]


def delete_credential_template(engine, template_id: int) -> bool:
    """
    åˆ é™¤å‡­æ®æ¨¡æ¿
    :param engine: SQLAlchemy å¼•æ“
    :param template_id: æ¨¡æ¿ID
    :return: æ˜¯å¦æˆåŠŸåˆ é™¤ï¼ˆboolï¼‰
    """
    table = models.credential_templates_table

    with engine.connect() as conn:
        stmt = delete(table).where(table.c.id == template_id)
        result = conn.execute(stmt)
        conn.commit()
        return result.rowcount > 0

def update_pj(engine: Engine, template_id: int, pj: CredentialTemplateCreate) -> dict:
    stmt = (
        update(credential_templates_table)
        .where(credential_templates_table.c.id == template_id)
        .values(**pj.__dict__)
    )
    with engine.begin() as conn:
        try:
            result = conn.execute(stmt)
            if result.rowcount == 0:
                return None
            # è¿”å›æ›´æ–°åçš„æ•°æ®
            select_stmt = select(credential_templates_table).where(credential_templates_table.c.id == template_id)
            row = conn.execute(select_stmt).mappings().first()
            return dict(row)
        except IntegrityError as e:
            conn.rollback()  # å›æ»šäº‹åŠ¡
            # æ£€æŸ¥æ˜¯å¦æ˜¯åç§°é‡å¤
            if "UNIQUE constraint failed: credential_templates.name" in str(e) or "Duplicate entry" in str(e):
                raise HTTPException(
                    status_code=400,
                    detail="å‡­æ®æ¨¡æ¿åç§°å·²å­˜åœ¨ï¼Œè¯·ä½¿ç”¨å…¶ä»–åç§°"
                )
            else:
                raise HTTPException(
                    status_code=400,
                    detail="æ•°æ®æ ¡éªŒå¤±è´¥"
                )
        except Exception as e:
            conn.rollback()
            raise HTTPException(
                status_code=500,
                detail="æœåŠ¡å™¨å†…éƒ¨é”™è¯¯"
            )








# ä»»åŠ¡ç®¡ç†
def create_cron_job(engine: Engine, job: schemas.CronJobCreate) -> dict:
    data = job.model_dump()
    stmt = insert(models.cron_jobs_table).values(**data)
    with engine.begin() as conn:
        result = conn.execute(stmt)
        job_id = result.inserted_primary_key[0]
        return {"id": job_id, **data}  # âœ… è¿”å›å®Œæ•´å¯¹è±¡

def get_cron_jobs(engine: Engine, node_ids: list[int] = None) -> list[dict]:
    stmt = (
        select(models.cron_jobs_table)
        .join(
            models.nodes_table,
            models.cron_jobs_table.c.node_id == models.nodes_table.c.id
        )
        .where(models.nodes_table.c.is_active.is_(True))
        .order_by(models.cron_jobs_table.c.name, models.nodes_table.c.name)
    )

    # å¤šèŠ‚ç‚¹ç­›é€‰
    if node_ids and len(node_ids) > 0:
        stmt = stmt.where(models.cron_jobs_table.c.node_id.in_(node_ids))
    with engine.connect() as conn:
        result = conn.execute(stmt)
        jobs = []
        for row in result.mappings():
            job_dict = dict(row)

            # è®¡ç®—ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´
            try:
                if job_dict['is_active']:
                    cron = croniter(job_dict['schedule'], datetime.now())
                    next_run = cron.get_next(datetime)
                    job_dict['next_run'] = next_run.isoformat()
                else:
                    job_dict['next_run'] = None
            except Exception:
                job_dict['next_run'] = None

            jobs.append(job_dict)
        return jobs

# æ‰§è¡Œä»»åŠ¡
def execute_job(engine: Engine, job_id: int, triggered_by: str = "manual") -> dict:
    # è·å–ä»»åŠ¡å’ŒèŠ‚ç‚¹ï¼ˆæå‰éªŒè¯ï¼‰
    with engine.connect() as conn:
        job_stmt = select(models.cron_jobs_table).where(models.cron_jobs_table.c.id == job_id)
        job = conn.execute(job_stmt).mappings().first()
        if not job:
            scheduler.remove_job(job_id, 'è¯¥ä»»åŠ¡ä¸å­˜åœ¨')
            raise ValueError(f"ä»»åŠ¡ {job_id} ä¸å­˜åœ¨ï¼Œå·²ç§»é™¤è®¡åˆ’")

        node_stmt = select(models.nodes_table).where(models.nodes_table.c.id == job['node_id'])
        node = conn.execute(node_stmt).mappings().first()
        if not node:
            scheduler.remove_job(job_id, f"ä»»åŠ¡ {job_id} çš„èŠ‚ç‚¹{job['node_id']}ä¸å­˜åœ¨")
            raise ValueError(f"ä»»åŠ¡ {job_id} çš„èŠ‚ç‚¹{job['node_id']}ä¸å­˜åœ¨ï¼Œå·²ç§»é™¤è®¡åˆ’")

    # åˆ›å»ºæ‰§è¡Œè®°å½•
    stmt = insert(models.job_executions_table).values(
        job_id=job_id,
        start_time=datetime.now(),
        status="running",
        triggered_by=triggered_by
    )
    with engine.begin() as conn:
        result = conn.execute(stmt)
        execution_id = result.inserted_primary_key[0]
        print(f"âœ… ä»»åŠ¡è°ƒåº¦ï¼šæ—¶é—´ï¼ˆ{datetime.now().replace(second=0, microsecond=0)}ï¼‰ï¼Œè®¾å¤‡ï¼ˆ{node['name']}ï¼‰ï¼Œä»»åŠ¡ï¼ˆ{job['name']}ï¼‰ï¼Œè§¦å‘æ–¹å¼ï¼ˆ{triggered_by}ï¼‰")

    def run_task():
        ssh = None
        try:
            # åˆ›å»ºåœæ­¢äº‹ä»¶
            execution_manager.create_execution(execution_id)

            ssh = SSHClient(schemas.NodeRead(**node))
            ssh.connect()

            initial_log = {"status": "running", "output": "æ­£åœ¨è¿æ¥...\n", "error": "", "end_time": None}
            ws_manager.send_log_sync(execution_id, initial_log)

            _, stdout, stderr = ssh.client.exec_command(job['command'], timeout=60)
            output_buffer = []
            error_buffer = []

            while True:
                # æ£€æŸ¥æ˜¯å¦éœ€è¦ä¸­æ–­
                if execution_manager.should_stop(execution_id):
                    raise ExecutionCancelledError("ä»»åŠ¡å·²è¢«ç”¨æˆ·ä¸­æ–­")
                if stdout.channel.recv_ready():
                    line = stdout.channel.recv(1024).decode('utf-8', errors='replace')
                    if line:
                        output_buffer.append(line)
                        log_data = {
                            "status": "running",
                            "output": line,
                            "error": "",
                            "end_time": None
                        }
                        ws_manager.send_log_sync(execution_id, log_data)
                if stderr.channel.recv_stderr_ready():
                    line = stderr.channel.recv_stderr(1024).decode('utf-8', errors='replace')
                    if line:
                        error_buffer.append(line)
                        log_data = {
                            "status": "running",
                            "output": "",
                            "error": line,
                            "end_time": None
                        }
                        ws_manager.send_log_sync(execution_id, log_data)

                if stdout.channel.exit_status_ready():
                    # stdout å…œåº•
                    while stdout.channel.recv_ready():
                        output_buffer.append(
                            stdout.channel.recv(4096).decode("utf-8", errors="replace")
                        )

                    # stderr å…œåº•
                    while stderr.channel.recv_stderr_ready():
                        error_buffer.append(
                            stderr.channel.recv_stderr(4096).decode("utf-8", errors="replace")
                        )
                    break
            exit_code = stdout.channel.recv_exit_status()
            print(f'é€€å‡ºç ï¼š{exit_code}')
            status = "success" if exit_code == 0 else "failed"
            final_log = {
                "status": status,
                "output": "".join(output_buffer),
                "error": "".join(error_buffer),
                "end_time": datetime.now().isoformat()
            }
            ws_manager.send_log_sync(execution_id, final_log)
            _update_execution_log(engine, execution_id, "".join(output_buffer), "".join(error_buffer), status)
        except ExecutionCancelledError as e:
            # ğŸ‘‡ ç”¨æˆ·ä¸­æ–­ï¼šçŠ¶æ€ = cancelled
            error_msg = str(e)
            final_log = {
                "status": "cancelled",
                "output": "".join(output_buffer) if 'output_buffer' in locals() else "",
                "error": error_msg,
                "end_time": datetime.now().isoformat()
            }
            ws_manager.send_log_sync(execution_id, final_log)
            _update_execution_log(engine, execution_id, final_log["output"], error_msg, "cancelled")
        except Exception as e:
            error_msg = str(e)
            final_log = {
                "status": "failed",
                "output": "",
                "error": error_msg,
                "end_time": datetime.now().isoformat()
            }
            ws_manager.send_log_sync(execution_id, final_log)
            _update_execution_log(engine, execution_id, "", error_msg, "failed")
        finally:
            if ssh:
                ssh.close()
            # æ¸…ç†èµ„æº
            execution_manager.cleanup(execution_id)
            ws_manager.cleanup(execution_id)

    threading.Thread(target=run_task, daemon=True).start()

    # âœ… è¿”å›åˆå§‹æ‰§è¡Œè®°å½•
    return get_execution(engine, execution_id)

def update_cron_job(engine, job_id: int, update_data: dict) -> bool:
    with engine.connect() as conn:
        stmt = (
            update(models.cron_jobs_table)
            .where(models.cron_jobs_table.c.id == job_id)
            .values(**update_data)
        )
        result = conn.execute(stmt)
        conn.commit()
        return result.rowcount > 0
def get_cron_job(engine, job_id: int):
    with engine.connect() as conn:
        query = models.cron_jobs_table.select().where(models.cron_jobs_table.c.id == job_id)
        result = conn.execute(query).fetchone()
        return result._asdict() if result else None

# è·å–æ‰§è¡Œè®°å½•
def get_executions(engine: Engine, job_id: int, limit: int = 10) -> list[dict]:
    stmt = (
        select(models.job_executions_table)
        .where(models.job_executions_table.c.job_id == job_id)
        .order_by(models.job_executions_table.c.start_time.desc())
        .limit(limit)
    )
    with engine.connect() as conn:
        result = conn.execute(stmt)
        return [dict(row) for row in result.mappings()]

def get_execution(engine: Engine, execution_id: int) -> dict:
    stmt = select(models.job_executions_table).where(models.job_executions_table.c.id == execution_id)
    with engine.connect() as conn:
        result = conn.execute(stmt).mappings().first()
        return dict(result) if result else None

# æ‰¹é‡æ‰§è¡Œ
def execute_jobs(engine: Engine, request: schemas.ManualExecutionRequest) -> list[dict]:
    results = []
    for job_id in request.job_ids:
        execution = execute_job(engine, job_id, "manual")
        results.append(execution)
    return results

def toggle_job_status(engine: Engine, job_id: int, is_active: bool) -> bool:
    stmt = (
        update(models.cron_jobs_table)
        .where(models.cron_jobs_table.c.id == job_id)
        .values(is_active=is_active)
    )
    with engine.begin() as conn:
        result = conn.execute(stmt)
        if result.rowcount == 0:
            return False

        job_stmt = select(models.cron_jobs_table).where(models.cron_jobs_table.c.id == job_id)
        job = conn.execute(job_stmt).mappings().first()
        if not job:
            return False

        if is_active:
            scheduler.add_job(job)
        else:
            scheduler.remove_job(job_id, job['name'])
        return True

def remove_job(engine: Engine, job_id: int) -> bool:
    with engine.begin() as conn:
        job_stmt = select(models.cron_jobs_table).where(models.cron_jobs_table.c.id == job_id)
        job = conn.execute(job_stmt).mappings().first()
        if not job:
            return False

        stmt = delete(models.cron_jobs_table).where(models.cron_jobs_table.c.id == job_id)
        result = conn.execute(stmt)
        scheduler.remove_job(job_id, job['name'])
        return result.rowcount > 0

# âœ… ä¿®æ­£å‚æ•°é¡ºåºï¼šengine æ”¾ç¬¬ä¸€ä½
def _update_execution_log(engine: Engine, execution_id: int, output: str, error: str, status: str):
    max_length = 5000
    truncated_output = output[-max_length:] if len(output) > max_length else output
    truncated_error = error[-max_length:] if len(error) > max_length else error

    stmt = (
        update(models.job_executions_table)
        .where(models.job_executions_table.c.id == execution_id)
        .values(
            output=truncated_output,
            error=truncated_error,
            status=status,
            end_time=datetime.now() if status in ["success", "failed"] else None
        )
    )
    with engine.begin() as conn:
        conn.execute(stmt)



def get_next_crons(cron: schemas.CronReq) -> list[dict]:
    cron = croniter(cron.cron, datetime.now())
    # è·å–æœ€è¿‘çš„5æ¬¡æ‰§è¡Œæ—¶é—´
    recent_runs = []
    for _ in range(5):
        next_run = cron.get_next(datetime)
        recent_runs.append(schemas.CronNextRes(next_run=next_run.isoformat()))
    return recent_runs
